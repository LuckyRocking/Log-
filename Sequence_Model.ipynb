{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F,CrossEntropyLoss\n",
    "from torch import optim\n",
    "from torch.nn import LSTM,Linear\n",
    "import math\n",
    "import copy\n",
    "from typing import Callable, Any, Optional, Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"\"\"克隆N层一模一样的\n",
    "    \"\"\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "\n",
    "class Api2resultmodel(nn.Module):\n",
    "    '''Api--->result Sequence model'''\n",
    "    def __init__(self,hidden_size,result_channels,*args, **kwargs) -> None:\n",
    "        super(Api2resultmodel,self).__init__()\n",
    "        self.Linear=nn.Linear(hidden_size,result_channels)\n",
    "    def forward(self,x):\n",
    "        results_proba=F.softmax(self.Linear(x))\n",
    "        return results_proba\n",
    "   \n",
    "\n",
    "class Api_Sequence2Result_Sequence_finddif_model(nn.Module):\n",
    "    '''Api_Sequence to result_Sequence_to next_Api_model'''\n",
    "    def __init__(self,Api_dim,Api_class_nums,windows_size,hidden_layers1,hidden_layers2,result_channels,lstm1_units,lstm2_units,lstm3_units,lstm4_units,Api2result_Basic: Optional[Callable[..., nn.Module]] = None,**kwargs:Any) -> None:\n",
    "        super(Api_Sequence2Result_Sequence_finddif_model,self).__init__()\n",
    "        if Api2result_Basic==None:\n",
    "            Api2result_Basic=Api2resultmodel(hidden_layers1,result_channels)\n",
    "        \n",
    "        #####first_dim=batch_size\n",
    "        self.lstm1=nn.LSTM(input_size=Api_dim,hidden_size=hidden_layers1,num_layers=lstm1_units,batch_first=True,**kwargs)        \n",
    "       \n",
    "        self.Linear_Block=clones(Api2result_Basic,windows_size)\n",
    "\n",
    "        self.lstm2=nn.LSTM(input_size=result_channels,hidden_size=hidden_layers2,num_layers=lstm2_units,batch_first=True,**kwargs)\n",
    "\n",
    "        self.apilstm1=nn.LSTM(input_size=Api_dim,hidden_size=hidden_layers2,num_layers=lstm3_units,batch_first=True,**kwargs)\n",
    "\n",
    "        self.apilstm2=nn.LSTM(input_size=Api_dim,hidden_size=hidden_layers2,num_layers=lstm4_units,batch_first=True,**kwargs)\n",
    "\n",
    "        self.Flatten1=nn.Flatten()\n",
    "\n",
    "        self.Dropout=nn.Dropout(0.1)\n",
    "\n",
    "        self.ApiLinear=nn.Linear(hidden_layers2*windows_size+(windows_size+(windows_size)//2)*hidden_layers2,Api_class_nums)\n",
    "    \n",
    "\n",
    "    def forward(self,window_sizedata,Dropout=True):\n",
    "        #forward \n",
    "        #faster compute\n",
    "        window_sizedata=torch.tensor(window_sizedata) if type(window_sizedata)!=torch.tensor else window_sizedata\n",
    "        if window_sizedata.dim()==2:\n",
    "            window_sizedata=window_sizedata.reshape(1,window_sizedata.size(0),window_sizedata.size(1))\n",
    "        # batch forward \n",
    "         #to get output of everystep and the outputdim of everystep is hidden_size     \n",
    "        window_sequence=self.lstm1(window_sizedata)[0]    \n",
    "            \n",
    "        api2result_sequence=torch.tensor([l(window_sequence[:,idx,:]).tolist() for idx,l in enumerate(self.Linear_Block)]).permute(1,0,2)\n",
    "        #utilize info of api->result_sequence to next lstm\n",
    "        result_sequence=self.lstm2(api2result_sequence)[0]\n",
    "         \n",
    "        #bigger windowsize lstm\n",
    "        coarse_Apisequence_output=self.apilstm1(window_sizedata)[0]\n",
    "\n",
    "        #smaller windowsize lstm\n",
    "        fine_Apisequence_output=self.apilstm2(window_sizedata[:,-(window_sizedata).size(1)//2:,])[0]   \n",
    "        \n",
    "        Apisequence=torch.concat([coarse_Apisequence_output,fine_Apisequence_output],axis=1) \n",
    "        \n",
    "        #utilize result_sequence to class\n",
    "        result_sequence_flatten=self.Flatten1(result_sequence)\n",
    "\n",
    "        api_sequence_flatten=self.Flatten1(Apisequence)\n",
    "        \n",
    "        all_suquence=torch.concat([result_sequence_flatten,api_sequence_flatten],axis=1) \n",
    "        \n",
    "        if Dropout:\n",
    "        #Dropout \n",
    "            allsequence_afdpt=self.Dropout(all_suquence)\n",
    "        #class\n",
    "            Api_class_proba=F.softmax(self.ApiLinear(allsequence_afdpt))\n",
    "        else:\n",
    "            Api_class_proba=F.softmax(self.ApiLinear(all_suquence))\n",
    "        return  api2result_sequence,Api_class_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Lstmlocal_find_sequence_dif_model(nn.Module):\n",
    "    def __init__(self, Api_dim,Api_class,hidden_layers,bigger_window_size=10,smaller_window_size=5, **kwargs) -> None:\n",
    "        super(Lstmlocal_find_sequence_dif_model,self).__init__()\n",
    "        #define windows size \n",
    "        self.bigger_window_size=bigger_window_size\n",
    "        \n",
    "        self.smaller_window_size=smaller_window_size\n",
    "\n",
    "        #window_size is 10\n",
    "        self.apilstm1=nn.LSTM(input_size=Api_dim,hidden_size=hidden_layers,batch_first=True,**kwargs)\n",
    "        #window_size is 5\n",
    "        self.apilstm2=nn.LSTM(input_size=Api_dim,hidden_size=hidden_layers,batch_first=True,**kwargs)\n",
    "        \n",
    "        self.Dropout=nn.Dropout(0.1)\n",
    "        \n",
    "        self.Flatten=nn.Flatten()\n",
    "\n",
    "        self.classlinear=nn.Linear((bigger_window_size+smaller_window_size)*hidden_layers,Api_class)\n",
    "\n",
    "    def forward(self,window_sizedata,Dropout=True):\n",
    "        #faster compute\n",
    "        window_sizedata=torch.tensor(window_sizedata) if type(window_sizedata)!=torch.tensor else window_sizedata\n",
    "        if window_sizedata.dim()==2:\n",
    "            window_sizedata=window_sizedata.reshape(1,window_sizedata.size(0),window_sizedata.size(1))\n",
    "        \n",
    "        \n",
    "        bigger_window_size=self.bigger_window_size\n",
    "\n",
    "        smaller_window_size=self.smaller_window_size\n",
    "\n",
    "        biggerlstmoutput=self.apilstm1(window_sizedata[:,-bigger_window_size:,])[0]\n",
    "\n",
    "        smallerlstmouput=self.apilstm2(window_sizedata[:,-smaller_window_size:,])[0]\n",
    "\n",
    "        if Dropout:\n",
    "\n",
    "            biggerlstmoutput=self.Dropout(biggerlstmoutput)\n",
    "\n",
    "            smallerlstmouput=self.Dropout(smallerlstmouput)\n",
    "        \n",
    "        api_sequence=torch.concat([biggerlstmoutput,smallerlstmouput],axis=1)\n",
    "\n",
    "\n",
    "        flatten_api_sequence=self.Flatten(api_sequence)\n",
    "\n",
    "        output=F.softmax(self.classlinear(flatten_api_sequence))\n",
    "        return  output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3364\\2526116284.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  window_sizedata=torch.tensor(window_sizedata) if type(window_sizedata)!=torch.tensor else window_sizedata\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3364\\2526116284.py:46: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output=F.softmax(self.classlinear(flatten_api_sequence))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15948])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lstmlocal_find_sequence_dif_model(Api_dim=8,Api_class=15948,hidden_layers=20,bigger_window_size=10,smaller_window_size=5)(torch.randn(100,8)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1dlocal_find_sequence_dif_model(nn.Module):\n",
    "    def __init__(self, windowsize,Api_dim,Api_classnum,outchannels1,outchannels2,*args, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        #bigger_conv1d to find local_dif\n",
    "        self.bigger_conv1d=nn.Conv1d(in_channels=Api_dim,out_channels=outchannels1,kernel_size=5,padding=2,bias=True)\n",
    "        \n",
    "        self.bn1=nn.BatchNorm1d(num_features=outchannels1,eps=0.001)\n",
    "\n",
    "        #smaller_cov1d to find local_dif\n",
    "        self.smaller_conv1d=nn.Conv1d(in_channels=Api_dim,out_channels=outchannels2,kernel_size=3,padding=1,bias=True)\n",
    "\n",
    "        self.bn2=nn.BatchNorm1d(num_features=outchannels2,eps=0.001)\n",
    "\n",
    "        self.flatten=nn.Flatten()\n",
    "\n",
    "        self.classlinear=nn.Linear(windowsize*(outchannels1+outchannels2),Api_classnum)\n",
    "\n",
    "    def forward(self,window_sizedata):\n",
    "        #faster compute \n",
    "        window_sizedata=torch.tensor(window_sizedata) if type(window_sizedata)!=torch.tensor else window_sizedata\n",
    "        if window_sizedata.dim()==2:\n",
    "            window_sizedata=window_sizedata.reshape(1,window_sizedata.size(0),window_sizedata.size(1))\n",
    "        \n",
    "        #need permuter window_sizedata to (batch_size,channels,api_windowsize)\n",
    "        window_sizedata=window_sizedata.permute(0,2,1)\n",
    "            \n",
    "        bigger_conv=self.bn1(self.bigger_conv1d(window_sizedata))\n",
    "\n",
    "        smaller_conv=self.bn2(self.smaller_conv1d(window_sizedata))\n",
    "\n",
    "        all_conv=torch.concat([bigger_conv,smaller_conv],axis=1).permute(0,2,1)\n",
    "        \n",
    "\n",
    "        all_conv=self.flatten(all_conv)\n",
    "\n",
    "        return F.softmax(self.classlinear(all_conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e450050b432e843bda3c41bf3272c133bfc370a7003f3e377e27f87a49ce1127"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
